{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa86af0a-c983-4d5c-809e-24b20ca96045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 71238, done.\u001b[K\n",
      "remote: Counting objects: 100% (1012/1012), done.\u001b[K\n",
      "remote: Compressing objects: 100% (552/552), done.\u001b[K\n",
      "remote: Total 71238 (delta 645), reused 638 (delta 377), pack-reused 70226 (from 1)\u001b[K\n",
      "Receiving objects: 100% (71238/71238), 50.35 MiB | 10.18 MiB/s, done.\n",
      "Resolving deltas: 100% (52540/52540), done.\n",
      "Updating files: 100% (1579/1579), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ab2d21-c633-43bb-9466-edf0ee782fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.4.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Collecting safetensors>=0.4.3 (from accelerate)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m225.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m215.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m152.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m154.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, tqdm, safetensors, regex, protobuf, fsspec, huggingface_hub, tokenizers, accelerate, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed accelerate-0.34.2 fsspec-2024.9.0 huggingface_hub-0.25.1 protobuf-5.28.2 regex-2024.9.11 safetensors-0.4.5 sentencepiece-0.2.0 tokenizers-0.20.0 tqdm-4.66.5 transformers-4.45.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub accelerate tokenizers protobuf transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e286f688-7e6c-4799-b4fc-fc2648a2199f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./diffusers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers==0.31.0.dev0) (4.6.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (0.25.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0) (9.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.31.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0) (2022.12.7)\n",
      "Building wheels for collected packages: diffusers\n",
      "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.31.0.dev0-py3-none-any.whl size=2778081 sha256=773e13b06c125c69c27fa20135d7d38c9f703eeb4dbe59f9e9ea7f74504570fb\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ia4yjs_o/wheels/0f/20/c8/51c98dd92d3452e41884e999b329516f339b1c440542fc729e\n",
      "Successfully built diffusers\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.31.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ./diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c14e6ca-000a-4d25-8f91-11c4a4c63159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f9ec0be4a64dbba9cfef652f98c066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208ad055359e4a9991cf7280c38bd620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %env CUDA_LAUNCH_BLOCKING=1\n",
    "import torch\n",
    "from pipeline_cogvideox import CogVideoXPipeline\n",
    "from transformer_cogvideox_v2 import CogVideoXTransformer3DModel\n",
    "from sampler_cogvideox import CogVideoXDDIMScheduler\n",
    "\n",
    "prompt = \"A panda, dressed in a small, red jacket and a tiny hat, sits on a wooden stool in a serene bamboo forest. The panda's fluffy paws strum a miniature acoustic guitar, producing soft, melodic tunes. Nearby, a few other pandas gather, watching curiously and some clapping in rhythm. Sunlight filters through the tall bamboo, casting a gentle glow on the scene. The panda's face is expressive, showing concentration and joy as it plays. The background includes a small, flowing stream and vibrant green foliage, enhancing the peaceful and magical atmosphere of this unique musical performance.\"\n",
    "\n",
    "transformer = CogVideoXTransformer3DModel.from_pretrained(\n",
    "    \"THUDM/CogVideoX-2b\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    subfolder=\"transformer\"\n",
    ")\n",
    "scheduler = CogVideoXDDIMScheduler.from_pretrained(\n",
    "    \"THUDM/CogVideoX-2b\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    subfolder=\"scheduler\"\n",
    ")\n",
    "pipe = CogVideoXPipeline.from_pretrained(\n",
    "    \"THUDM/CogVideoX-2b\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    transformer=transformer,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5bf0c9-42b8-4e1f-9bdc-9b31287c0cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CogVideoXPipeline {\n",
       "  \"_class_name\": \"CogVideoXPipeline\",\n",
       "  \"_diffusers_version\": \"0.31.0.dev0\",\n",
       "  \"_name_or_path\": \"THUDM/CogVideoX-2b\",\n",
       "  \"scheduler\": [\n",
       "    \"sampler_cogvideox\",\n",
       "    \"CogVideoXDDIMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"T5EncoderModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"T5Tokenizer\"\n",
       "  ],\n",
       "  \"transformer\": [\n",
       "    \"transformer_cogvideox_v2\",\n",
       "    \"CogVideoXTransformer3DModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKLCogVideoX\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74108d0b-bcca-45a1-9c9a-8bd1cccd6677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23022389e049493a9bc32404ec7e535d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([999, 979, 959, 939], device='cuda:0')\n",
      "tensor([999, 979, 959, 939, 999, 979, 959, 939], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/inversion/fifo/pipeline_cogvideox.py:678: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(timesteps)[i:i+video_length_frames]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([979, 959, 939, 919], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([979, 959, 939, 919], device='cuda:0')\n",
      "tensor([979, 959, 939, 919, 979, 959, 939, 919], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([959, 939, 919, 899], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([959, 939, 919, 899], device='cuda:0')\n",
      "tensor([959, 939, 919, 899, 959, 939, 919, 899], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([939, 919, 899, 879], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([939, 919, 899, 879], device='cuda:0')\n",
      "tensor([939, 919, 899, 879, 939, 919, 899, 879], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([919, 899, 879, 859], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([919, 899, 879, 859], device='cuda:0')\n",
      "tensor([919, 899, 879, 859, 919, 899, 879, 859], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([899, 879, 859, 839], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([899, 879, 859, 839], device='cuda:0')\n",
      "tensor([899, 879, 859, 839, 899, 879, 859, 839], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([879, 859, 839, 819], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([879, 859, 839, 819], device='cuda:0')\n",
      "tensor([879, 859, 839, 819, 879, 859, 839, 819], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([859, 839, 819, 799], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([859, 839, 819, 799], device='cuda:0')\n",
      "tensor([859, 839, 819, 799, 859, 839, 819, 799], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([839, 819, 799, 779], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([839, 819, 799, 779], device='cuda:0')\n",
      "tensor([839, 819, 799, 779, 839, 819, 799, 779], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([819, 799, 779, 759], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([819, 799, 779, 759], device='cuda:0')\n",
      "tensor([819, 799, 779, 759, 819, 799, 779, 759], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([799, 779, 759, 739], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([799, 779, 759, 739], device='cuda:0')\n",
      "tensor([799, 779, 759, 739, 799, 779, 759, 739], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([779, 759, 739, 719], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([779, 759, 739, 719], device='cuda:0')\n",
      "tensor([779, 759, 739, 719, 779, 759, 739, 719], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([759, 739, 719, 699], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([759, 739, 719, 699], device='cuda:0')\n",
      "tensor([759, 739, 719, 699, 759, 739, 719, 699], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([739, 719, 699, 679], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([739, 719, 699, 679], device='cuda:0')\n",
      "tensor([739, 719, 699, 679, 739, 719, 699, 679], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([719, 699, 679, 659], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([719, 699, 679, 659], device='cuda:0')\n",
      "tensor([719, 699, 679, 659, 719, 699, 679, 659], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([699, 679, 659, 639], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([699, 679, 659, 639], device='cuda:0')\n",
      "tensor([699, 679, 659, 639, 699, 679, 659, 639], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([679, 659, 639, 619], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([679, 659, 639, 619], device='cuda:0')\n",
      "tensor([679, 659, 639, 619, 679, 659, 639, 619], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([659, 639, 619, 599], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([659, 639, 619, 599], device='cuda:0')\n",
      "tensor([659, 639, 619, 599, 659, 639, 619, 599], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([639, 619, 599, 579], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([639, 619, 599, 579], device='cuda:0')\n",
      "tensor([639, 619, 599, 579, 639, 619, 599, 579], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([619, 599, 579, 559], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([619, 599, 579, 559], device='cuda:0')\n",
      "tensor([619, 599, 579, 559, 619, 599, 579, 559], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([599, 579, 559, 539], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([599, 579, 559, 539], device='cuda:0')\n",
      "tensor([599, 579, 559, 539, 599, 579, 559, 539], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([579, 559, 539, 519], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([579, 559, 539, 519], device='cuda:0')\n",
      "tensor([579, 559, 539, 519, 579, 559, 539, 519], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([559, 539, 519, 499], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([559, 539, 519, 499], device='cuda:0')\n",
      "tensor([559, 539, 519, 499, 559, 539, 519, 499], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([539, 519, 499, 479], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([539, 519, 499, 479], device='cuda:0')\n",
      "tensor([539, 519, 499, 479, 539, 519, 499, 479], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([519, 499, 479, 459], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([519, 499, 479, 459], device='cuda:0')\n",
      "tensor([519, 499, 479, 459, 519, 499, 479, 459], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([499, 479, 459, 439], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([499, 479, 459, 439], device='cuda:0')\n",
      "tensor([499, 479, 459, 439, 499, 479, 459, 439], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([479, 459, 439, 419], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([479, 459, 439, 419], device='cuda:0')\n",
      "tensor([479, 459, 439, 419, 479, 459, 439, 419], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([459, 439, 419, 399], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([459, 439, 419, 399], device='cuda:0')\n",
      "tensor([459, 439, 419, 399, 459, 439, 419, 399], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([439, 419, 399, 379], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([439, 419, 399, 379], device='cuda:0')\n",
      "tensor([439, 419, 399, 379, 439, 419, 399, 379], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([419, 399, 379, 359], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([419, 399, 379, 359], device='cuda:0')\n",
      "tensor([419, 399, 379, 359, 419, 399, 379, 359], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([399, 379, 359, 339], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([399, 379, 359, 339], device='cuda:0')\n",
      "tensor([399, 379, 359, 339, 399, 379, 359, 339], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([379, 359, 339, 319], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([379, 359, 339, 319], device='cuda:0')\n",
      "tensor([379, 359, 339, 319, 379, 359, 339, 319], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([359, 339, 319, 299], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([359, 339, 319, 299], device='cuda:0')\n",
      "tensor([359, 339, 319, 299, 359, 339, 319, 299], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([339, 319, 299, 279], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([339, 319, 299, 279], device='cuda:0')\n",
      "tensor([339, 319, 299, 279, 339, 319, 299, 279], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([319, 299, 279, 259], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([319, 299, 279, 259], device='cuda:0')\n",
      "tensor([319, 299, 279, 259, 319, 299, 279, 259], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([299, 279, 259, 239], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([299, 279, 259, 239], device='cuda:0')\n",
      "tensor([299, 279, 259, 239, 299, 279, 259, 239], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([279, 259, 239, 219], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([279, 259, 239, 219], device='cuda:0')\n",
      "tensor([279, 259, 239, 219, 279, 259, 239, 219], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([259, 239, 219, 199], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([259, 239, 219, 199], device='cuda:0')\n",
      "tensor([259, 239, 219, 199, 259, 239, 219, 199], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([239, 219, 199, 179], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([239, 219, 199, 179], device='cuda:0')\n",
      "tensor([239, 219, 199, 179, 239, 219, 199, 179], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([219, 199, 179, 159], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([219, 199, 179, 159], device='cuda:0')\n",
      "tensor([219, 199, 179, 159, 219, 199, 179, 159], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([199, 179, 159, 139], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([199, 179, 159, 139], device='cuda:0')\n",
      "tensor([199, 179, 159, 139, 199, 179, 159, 139], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([179, 159, 139, 119], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([179, 159, 139, 119], device='cuda:0')\n",
      "tensor([179, 159, 139, 119, 179, 159, 139, 119], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([159, 139, 119,  99], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([159, 139, 119,  99], device='cuda:0')\n",
      "tensor([159, 139, 119,  99, 159, 139, 119,  99], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([139, 119,  99,  79], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([139, 119,  99,  79], device='cuda:0')\n",
      "tensor([139, 119,  99,  79, 139, 119,  99,  79], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([119,  99,  79,  59], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([119,  99,  79,  59], device='cuda:0')\n",
      "tensor([119,  99,  79,  59, 119,  99,  79,  59], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([99, 79, 59, 39], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([99, 79, 59, 39], device='cuda:0')\n",
      "tensor([99, 79, 59, 39, 99, 79, 59, 39], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([79, 59, 39, 19], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([8])\n",
      "tensor([79, 59, 39, 19], device='cuda:0')\n",
      "tensor([79, 59, 39, 19, 79, 59, 39, 19], device='cuda:0')\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "cogvideoxblock torch.Size([8, 512])\n",
      "ada torch.Size([8, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([59, 39, 19, -1], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[ True]],\n",
      "\n",
      "          [[ True]],\n",
      "\n",
      "          [[ True]],\n",
      "\n",
      "          [[ True]]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 16, 60, 90])\n",
      "torch.Size([6])\n",
      "tensor([59, 39, 19], device='cuda:0')\n",
      "tensor([59, 39, 19, 59, 39, 19], device='cuda:0')\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "cogvideoxblock torch.Size([6, 512])\n",
      "ada torch.Size([6, 512]) torch.Size([2, 2700, 1920])\n",
      "prev_timestep tensor([39, 19, -1], device='cuda:0')\n",
      "tensor([[[[[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[False]],\n",
      "\n",
      "          [[ True]],\n",
      "\n",
      "          [[ True]],\n",
      "\n",
      "          [[ True]],\n",
      "\n",
      "          [[ True]],\n",
      "\n",
      "          [[ True]]]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (15) must match the size of tensor b (16) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m video \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_videos_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m480\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m720\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# generator=torch.Generator(device=\"cuda\").manual_seed(42),\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mframes[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/inversion/fifo/pipeline_cogvideox.py:706\u001b[0m, in \u001b[0;36mCogVideoXPipeline.__call__\u001b[0;34m(self, prompt, negative_prompt, height, width, num_frames, num_inference_steps, timesteps, guidance_scale, use_dynamic_cfg, num_videos_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, output_type, return_dict, callback_on_step_end, callback_on_step_end_tensor_inputs, max_sequence_length)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;66;03m# compute the previous noisy sample x_t -> x_t-1\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler, CogVideoXDPMScheduler):\n\u001b[0;32m--> 706\u001b[0m     latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_step_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    708\u001b[0m     latents, old_pred_original_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep(\n\u001b[1;32m    709\u001b[0m         noise_pred,\n\u001b[1;32m    710\u001b[0m         old_pred_original_sample,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    715\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    716\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/inversion/fifo/sampler_cogvideox.py:405\u001b[0m, in \u001b[0;36mCogVideoXDDIMScheduler.step\u001b[0;34m(self, model_output, timestep, sample, eta, use_clipped_model_output, generator, variance_noise, return_dict)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# pred_epsilon = (sample - alpha_prod_t ** (0.5) * pred_original_sample) / beta_prod_t ** (0.5)\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 405\u001b[0m     pred_original_sample \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43malpha_prod_t\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m \u001b[38;5;241m-\u001b[39m (beta_prod_t\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m*\u001b[39m model_output\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# pred_epsilon = (alpha_prod_t**0.5) * model_output + (beta_prod_t**0.5) * sample\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_type given as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprediction_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be one of `epsilon`, `sample`, or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `v_prediction`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (15) must match the size of tensor b (16) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "video = pipe(\n",
    "    prompt=prompt,\n",
    "    num_videos_per_prompt=1,\n",
    "    num_inference_steps=50,\n",
    "    num_frames=6,\n",
    "    guidance_scale=6,\n",
    "    height=480,\n",
    "    width=720,\n",
    "    # generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    ").frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc1a7b3-1e5c-4df5-bc6b-28bc8c75ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "60 * 90 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666638ee-a97c-4860-a633-fcf8bd68cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.index_select(pipe.scheduler.alphas_cumprod, 0, torch.tensor([0, 700]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89140d33-fa6e-4a32-8d93-d22cd1170363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display, Image as IPyImage\n",
    "\n",
    "# Assuming `image_list` is your list of PIL images\n",
    "# Example: creating some dummy images for the demonstration\n",
    "\n",
    "# Save images as a GIF to a file\n",
    "gif_path = 'my_animation.gif'\n",
    "video[0].save(gif_path, save_all=True, append_images=video[1:], loop=0, duration=500)\n",
    "\n",
    "# Display the GIF in Jupyter notebook\n",
    "display(IPyImage(filename=gif_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731c19bd-ae1c-46e9-9d35-6f97ebcc4656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "150a9c77-33a2-40ff-9825-2411124b110f",
   "metadata": {},
   "source": [
    "FIFO config:\n",
    "    num_partitions = 2\n",
    "    partition_Size = 16 #num of video frames to denoise in one go\n",
    "    f = partition_size // vae_temporal_scale_factor\n",
    "    total_num_frames = 1000 #num of total video frames\n",
    "    enable_lookahead_denoising = True\n",
    "Steps:\n",
    "    1. prepare latents. latent frames count = num_partitions * partition_size * 2(if look_ahead else 1)\n",
    "    2. latents shape = [2, 256 * f, 1920]\n",
    "       encoder_hidden_states = [2, 226, 512]\n",
    "       timesteps = [2, 512] -> [2*f, 512]\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e07f113-0833-4fe1-83aa-27202b24fa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51edd037-1169-45ab-9ec9-420f0795489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIFO Steps:\n",
    "    1. Prepare the initial noise\n",
    "    2. Prepare the latents, prompt embeds etc\n",
    "    3. Prepare the num of times fifo needs to run to get the total num frames\n",
    "    4. For each iteration, get the output frame, updated latents and write them to file. Consider the vae scale factor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4dc1e97-19d7-46e4-ba75-7a8dd2374cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7863ab623e8442db9b7995bbf2d489e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f400b21df5e64e418b1f1bb7f1ec9c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sampler_cogvideox import CogVideoXDDIMScheduler\n",
    "scheduler = CogVideoXDDIMScheduler.from_pretrained(\n",
    "    \"THUDM/CogVideoX-2b\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    subfolder=\"scheduler\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5597378b-0adc-4294-9932-41d207287ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d37561e-1120-4022-9209-482ddd526a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (model_output: torch.Tensor, timestep: int, sample: torch.Tensor, eta: float = 0.0, use_clipped_model_output: bool = False, generator=None, variance_noise: Optional[torch.Tensor] = None, return_dict: bool = True) -> Union[sampler_cogvideox.DDIMSchedulerOutput, Tuple]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.signature(scheduler.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ef3a06-3fb9-4d18-8dc0-4aa03b07440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting argparse\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e106f11b-b37d-487c-82ae-c502877d0af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f82d115ae0451e96da6df8604338de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3e5f5f80324abb9e3a9eb0e8bd1d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model_path MODEL_PATH]\n",
      "                             [--version {None,65x512x512,221x512x512,513x512x512}]\n",
      "                             [--num_frames NUM_FRAMES] [--height HEIGHT]\n",
      "                             [--width WIDTH] [--guidance_scale GUIDANCE_SCALE]\n",
      "                             [--num_sampling_steps NUM_SAMPLING_STEPS]\n",
      "                             [--queue_length QUEUE_LENGTH] [--fps FPS]\n",
      "                             [--text_prompt TEXT_PROMPT [TEXT_PROMPT ...]]\n",
      "                             [--video_length VIDEO_LENGTH]\n",
      "                             [--new_video_length NEW_VIDEO_LENGTH]\n",
      "                             [--num_partitions NUM_PARTITIONS]\n",
      "                             [--lookahead_denoising] [--output_dir OUTPUT_DIR]\n",
      "                             [--save_frames]\n",
      "ipykernel_launcher.py: error: argument --video_length/-f: invalid int value: '/root/.local/share/jupyter/runtime/kernel-e6e7f97c-fa1a-4522-871e-877e32177a8e.json'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:2507\u001b[0m, in \u001b[0;36mArgumentParser._get_value\u001b[0;34m(self, action, arg_string)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2507\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtype_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;66;03m# ArgumentTypeErrors indicate errors\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '/root/.local/share/jupyter/runtime/kernel-e6e7f97c-fa1a-4522-871e-877e32177a8e.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:1878\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1877\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1878\u001b[0m     namespace, args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError:\n",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:2091\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2090\u001b[0m     \u001b[38;5;66;03m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[0;32m-> 2091\u001b[0m     start_index \u001b[38;5;241m=\u001b[39m \u001b[43mconsume_optional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[38;5;66;03m# consume any positionals following the last Optional\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:2031\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action, args, option_string \u001b[38;5;129;01min\u001b[39;00m action_tuples:\n\u001b[0;32m-> 2031\u001b[0m     \u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moption_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stop\n",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:1939\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.take_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1938\u001b[0m seen_actions\u001b[38;5;241m.\u001b[39madd(action)\n\u001b[0;32m-> 1939\u001b[0m argument_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margument_strings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;66;03m# error if this argument is not allowed with other previously\u001b[39;00m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;66;03m# seen arguments, assuming that actions that use the default\u001b[39;00m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;66;03m# value don't really count as \"present\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:2474\u001b[0m, in \u001b[0;36mArgumentParser._get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2473\u001b[0m arg_string, \u001b[38;5;241m=\u001b[39m arg_strings\n\u001b[0;32m-> 2474\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_value(action, value)\n",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:2520\u001b[0m, in \u001b[0;36mArgumentParser._get_value\u001b[0;34m(self, action, arg_string)\u001b[0m\n\u001b[1;32m   2519\u001b[0m     msg \u001b[38;5;241m=\u001b[39m _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid \u001b[39m\u001b[38;5;132;01m%(type)s\u001b[39;00m\u001b[38;5;124m value: \u001b[39m\u001b[38;5;132;01m%(value)r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(action, msg \u001b[38;5;241m%\u001b[39m args)\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;66;03m# return the converted value\u001b[39;00m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument --video_length/-f: invalid int value: '/root/.local/share/jupyter/runtime/kernel-e6e7f97c-fa1a-4522-871e-877e32177a8e.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[2], line 194\u001b[0m\n\u001b[1;32m    192\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--save_frames\u001b[39m\u001b[38;5;124m\"\u001b[39m, action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_true\u001b[39m\u001b[38;5;124m'\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 194\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m args\u001b[38;5;241m.\u001b[39mnum_frames \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39margs\u001b[38;5;241m.\u001b[39mvideo_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:1845\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1845\u001b[0m     args, argv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argv:\n",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:1881\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1880\u001b[0m         err \u001b[38;5;241m=\u001b[39m _sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1881\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:2606\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2605\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[0;32m-> 2606\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/argparse.py:2593\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 2593\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:2119\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2117\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2118\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2119\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py:1435\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py:1326\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1323\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py:1173\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1166\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1171\u001b[0m ):\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py:1063\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1061\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1062\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1064\u001b[0m )\n\u001b[1;32m   1066\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1067\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py:1131\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "### IMPORTS\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "from pipeline_cogvideox import CogVideoXPipeline\n",
    "from transformer_cogvideox_v2 import CogVideoXTransformer3DModel\n",
    "from sampler_cogvideox import CogVideoXDDIMScheduler\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "checkpoint = \"THUDM/CogVideoX-2b\"\n",
    "dtype = torch.bfloat16\n",
    "device = \"cuda\"\n",
    "\n",
    "### INIT\n",
    "transformer = CogVideoXTransformer3DModel.from_pretrained(\n",
    "    checkpoint,\n",
    "    torch_dtype=dtype,\n",
    "    subfolder=\"transformer\"\n",
    ")\n",
    "scheduler = CogVideoXDDIMScheduler.from_pretrained(\n",
    "    checkpoint,\n",
    "    torch_dtype=dtype,\n",
    "    subfolder=\"scheduler\"\n",
    ")\n",
    "pipe = CogVideoXPipeline.from_pretrained(\n",
    "    checkpoint,\n",
    "    torch_dtype=dtype,\n",
    "    transformer=transformer,\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "print(\"model loading\")\n",
    "### FIFO Pipeline\n",
    "\n",
    "def shift_latents(latents, scheduler):\n",
    "    # shift latents\n",
    "    latents[:,:,:-1] = latents[:,:,1:].clone()\n",
    "\n",
    "    # add new noise to the last frame\n",
    "    latents[:,:,-1] = torch.randn_like(latents[:,:,-1]) * scheduler.init_noise_sigma\n",
    "\n",
    "    return latents\n",
    "\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # args.video_length a.k.a f = 16 or 48 need to check if to use video frames or video latents\n",
    "    # args.height\n",
    "    # args.width\n",
    "    # args.new_video_length #total num of frames in final video\n",
    "    # args.video_length #num of frames per iteration to be processed/denoised a.k.a partition size\n",
    "    # args.num_partitions\n",
    "    # args.queue_length = args.video_length * args.num_partitions\n",
    "    # args.num_sampling_steps = args.video_length * args.num_partitions\n",
    "    # args.lookahead_denoising\n",
    "    # args.max_queue_length = num of latents to keep in memory before\n",
    "    generator = torch.Generator('cuda').manual_seed(0)\n",
    "    fifo_video_frames = []\n",
    "    fifo_first_latents = []\n",
    "\n",
    "    new_video_length = (args.new_video_length - 1) // self.vae_scale_factor_temporal + 1\n",
    "    video_length = (args.video_length - 1) // self.vae_scale_factor_temporal + 1\n",
    "    \n",
    "    timesteps = pipe.scheduler.timesteps\n",
    "    timesteps = torch.flip(timesteps, [0])\n",
    "    if args.lookahead_denoising:\n",
    "        timesteps = torch.cat([torch.full((video_length//2,), timesteps[0]).to(timesteps.device), timesteps])\n",
    "\n",
    "    ## check this again\n",
    "    max_queue_length = len(timesteps)\n",
    "    bsz = 1\n",
    "    ch = pipe.transformer.config.in_channels\n",
    "    h = args.height // pipe.vae.vae_scale_factor[1]\n",
    "    w = args.width // pipe.vae.vae_scale_factor[2]\n",
    "    init_noise_shape = [bsz, ch, max_queue_length, h, w]\n",
    "    ## check this again - END\n",
    "\n",
    "    latents = self.prepare_latents(\n",
    "            batch_size * num_videos_per_prompt,\n",
    "            pipe.transformer.config.in_channels,\n",
    "            # num_frames,\n",
    "            max_queue_length,\n",
    "            args.height,\n",
    "            args.width,\n",
    "            dtype,\n",
    "            device,\n",
    "            generator,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    latents = randn_tensor(init_noise_shape, device=pipe.text_encoder.device, dtype=torch.float16)\n",
    "    \n",
    "    num_vae = (new_video_length - 1) // (video_length-1)\n",
    "    if (new_video_length - 1) % (video_length-1) != 0:\n",
    "        num_vae += 1\n",
    "    \n",
    "    num_iterations = num_vae * (video_length-1) + 1 + args.queue_length\n",
    "\n",
    "    for i in trange(num_iterations):\n",
    "        num_inference_steps_per_gpu = video_length\n",
    "        curr_timesteps = timesteps.clone()\n",
    "\n",
    "        if i < max_queue_length-1:\n",
    "            curr_timesteps[:-i-1] = curr_timesteps[-i-1]\n",
    "\n",
    "        for rank in reversed(range(2 * args.num_partitions if args.lookahead_denoising else args.num_partitions)):\n",
    "            if args.lookahead_denoising:\n",
    "                start_idx = (rank // 2) * num_inference_steps_per_gpu + (rank % 2) * (num_inference_steps_per_gpu // 2)\n",
    "            else:\n",
    "                start_idx = rank * num_inference_steps_per_gpu\n",
    "            midpoint_idx = start_idx + num_inference_steps_per_gpu // 2 + (rank % 2)\n",
    "            end_idx = start_idx + num_inference_steps_per_gpu\n",
    "            \n",
    "            t = curr_timesteps[start_idx:end_idx]\n",
    "            print(\"timesteps shape\", t.shape)\n",
    "            input_latents = latents[:,:,start_idx:end_idx].clone()\n",
    "\n",
    "            output_latents, first_latent, first_frame = pipe.fifo_onestep(prompt,\n",
    "                                    video_length=args.video_length,\n",
    "                                    height=args.height,\n",
    "                                    width=args.width,\n",
    "                                    num_inference_steps=args.num_sampling_steps,\n",
    "                                    guidance_scale=args.guidance_scale,\n",
    "                                    enable_temporal_attentions=not args.force_images,\n",
    "                                    num_images_per_prompt=1,\n",
    "                                    mask_feature=True,\n",
    "                                    latents=input_latents,\n",
    "                                    timesteps=t,\n",
    "                                    save_frames=args.save_frames,\n",
    "                                    )\n",
    "\n",
    "            if args.lookahead_denoising:\n",
    "                latents[:,:,midpoint_idx:end_idx] = output_latents[:,:,-(end_idx-midpoint_idx):]\n",
    "            else:\n",
    "                latents[:,:,start_idx:end_idx] = output_latents\n",
    "            del output_latents\n",
    "\n",
    "        latents = shift_latents(latents, videogen_pipeline.scheduler)\n",
    "\n",
    "        if i >= max_queue_length:\n",
    "            if args.save_frames:\n",
    "                output_path = os.path.join(fifo_dir, f\"frame_{i:04d}.png\")\n",
    "                imageio.mimwrite(output_path, first_frame, quality=9)  # highest quality is 10, lowest is 0\n",
    "            fifo_first_latents.append(first_latent)\n",
    "        fifo_vae_video_frames = []\n",
    "        \n",
    "    for i in range(num_vae):\n",
    "        target_latents = torch.cat(fifo_first_latents[i*(args.video_length-1):(i+1)*(args.video_length-1)+1], dim=2)\n",
    "        video = videogen_pipeline.decode_latents(target_latents)[0]\n",
    "\n",
    "        if i == 0:\n",
    "            fifo_vae_video_frames.append(video)\n",
    "        else:\n",
    "            fifo_vae_video_frames.append(video[1:])\n",
    "    \n",
    "    if num_vae > 0:\n",
    "        fifo_vae_video_frames = torch.cat(fifo_vae_video_frames, dim=0)\n",
    "        if args.output_dir is None:\n",
    "            output_vae_path = os.path.join(output_dir, \"fifo_vae.mp4\")\n",
    "        else:\n",
    "            output_vae_path = os.path.join(args.output_dir, f\"{prompt_save}.mp4\")\n",
    "        imageio.mimwrite(output_vae_path, fifo_vae_video_frames, fps=args.fps, quality=9)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_path\", type=str, default='LanguageBind/Open-Sora-Plan-v1.1.0')\n",
    "    parser.add_argument(\"--version\", type=str, default=None, choices=[None, '65x512x512', '221x512x512', '513x512x512'])\n",
    "    parser.add_argument(\"--num_frames\", type=int, default=65)\n",
    "    parser.add_argument(\"--height\", type=int, default=480)\n",
    "    parser.add_argument(\"--width\", type=int, default=720)\n",
    "    # parser.add_argument(\"--ae\", type=str, default='CausalVAEModel_4x8x8')\n",
    "    # parser.add_argument(\"--text_encoder_name\", type=str, default='DeepFloyd/t5-v1_1-xxl')\n",
    "    parser.add_argument(\"--guidance_scale\", type=float, default=7.5)\n",
    "    # parser.add_argument(\"--sample_method\", type=str, default=\"DDPM\")\n",
    "    parser.add_argument(\"--num_sampling_steps\", type=int, default=50)\n",
    "    parser.add_argument(\"--queue_length\", type=int, default=17)\n",
    "    parser.add_argument(\"--fps\", type=int, default=8)\n",
    "    # parser.add_argument(\"--run_time\", type=int, default=0)\n",
    "    parser.add_argument(\"--text_prompt\", nargs='+')\n",
    "    # parser.add_argument('--force_images', action='store_true')\n",
    "    # parser.add_argument('--tile_overlap_factor', type=float, default=0.25)\n",
    "    # parser.add_argument('--enable_tiling', action='store_true')\n",
    "    # parser.add_argument(\"--cache_dir\", type=str, default=\"./cache\")\n",
    "    parser.add_argument(\"--video_length\", \"-f\", type=int, default=17)\n",
    "    parser.add_argument(\"--new_video_length\", \"-N\", type=int, default=None)\n",
    "    parser.add_argument(\"--num_partitions\", \"-n\", type=int, default=4)\n",
    "    parser.add_argument(\"--lookahead_denoising\", \"-ld\", action='store_false', default=True)\n",
    "    parser.add_argument(\"--output_dir\", type=str, default=None, help=\"custom output directory\")\n",
    "    parser.add_argument(\"--save_frames\", action='store_true', default=False)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    assert args.num_frames == 4*args.video_length - 3\n",
    "\n",
    "    args.queue_length = args.video_length * args.num_partitions\n",
    "    args.num_sampling_steps = args.video_length * args.num_partitions\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcad4b8-3c32-4eef-88d5-23b8649b3aba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f497213997ce4b93959859e08e9b932c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f8b820a1c044a4aceb2bacd9846098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import CogVideoXPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "\n",
    "prompt = \"A panda, dressed in a small, red jacket and a tiny hat, sits on a wooden stool in a serene bamboo forest. The panda's fluffy paws strum a miniature acoustic guitar, producing soft, melodic tunes. Nearby, a few other pandas gather, watching curiously and some clapping in rhythm. Sunlight filters through the tall bamboo, casting a gentle glow on the scene. The panda's face is expressive, showing concentration and joy as it plays. The background includes a small, flowing stream and vibrant green foliage, enhancing the peaceful and magical atmosphere of this unique musical performance.\"\n",
    "\n",
    "pipe = CogVideoXPipeline.from_pretrained(\n",
    "    \"THUDM/CogVideoX-2b\",\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3becec10-b380-49b6-9b06-e1aa39aa5e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CogVideoXPipeline {\n",
       "  \"_class_name\": \"CogVideoXPipeline\",\n",
       "  \"_diffusers_version\": \"0.31.0.dev0\",\n",
       "  \"_name_or_path\": \"THUDM/CogVideoX-2b\",\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"CogVideoXDDIMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"T5EncoderModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"T5Tokenizer\"\n",
       "  ],\n",
       "  \"transformer\": [\n",
       "    \"diffusers\",\n",
       "    \"CogVideoXTransformer3DModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKLCogVideoX\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07153ca5-1b99-432a-9073-fbfaa993939d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2207c71141e04d5a8cdc2adc9333c1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video = pipe(\n",
    "    prompt=prompt,\n",
    "    num_videos_per_prompt=1,\n",
    "    num_inference_steps=50,\n",
    "    num_frames=5,\n",
    "    guidance_scale=6,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    "    output_type='latent',\n",
    ").frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c215d930-5ecc-4138-91e7-95d3d40f95c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c48765f8-aa5b-4a47-9efe-3d586cf3e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = pipe.decode_latents(video.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e0e8f05-f1ea-47e1-b5de-86ea4db5e63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 8, 480, 720])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8264e23a-fafb-4f98-a2ea-1e31d101ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b7be59-8155-41ff-bdb6-8861f65e49b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa0de3e0a0f47888fe848a5a0166a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b141876423de4fb88967923362c155ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import CogVideoXPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "\n",
    "prompt = \"A panda, dressed in a small, red jacket and a tiny hat, sits on a wooden stool in a serene bamboo forest. The panda's fluffy paws strum a miniature acoustic guitar, producing soft, melodic tunes. Nearby, a few other pandas gather, watching curiously and some clapping in rhythm. Sunlight filters through the tall bamboo, casting a gentle glow on the scene. The panda's face is expressive, showing concentration and joy as it plays. The background includes a small, flowing stream and vibrant green foliage, enhancing the peaceful and magical atmosphere of this unique musical performance.\"\n",
    "\n",
    "pipe = CogVideoXPipeline.from_pretrained(\n",
    "    \"THUDM/CogVideoX-2b\",\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2271608b-5abe-4286-96cf-700dcba5df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.vae = pipe.vae.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34dd523f-5f55-46f7-9737-6f9936d214f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.randn((1,1,16,60,90)).to('cuda').half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bcaceff-8fca-4f42-8987-0d1edd378ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 1, 60, 90])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.permute(0,2,1,3,4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01fc84a-661f-4675-ac62-a32e7170732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.vae.enable_tiling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f3afdf2-0127-4cea-bcac-d03f2bc27e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 2, 60, 90])\n",
      "frame_batch_size 2\n",
      "num_batches 1\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 44.34 GiB of which 86.81 MiB is free. Process 660831 has 44.25 GiB memory in use. Of the allocated memory 43.35 GiB is allocated by PyTorch, and 587.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_latents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/cogvideo/pipeline_cogvideox.py:350\u001b[0m, in \u001b[0;36mCogVideoXPipeline.decode_latents\u001b[0;34m(self, latents)\u001b[0m\n\u001b[1;32m    347\u001b[0m latents \u001b[38;5;241m=\u001b[39m latents\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)  \u001b[38;5;66;03m# [batch_size, num_channels, num_frames, height, width]\u001b[39;00m\n\u001b[1;32m    348\u001b[0m latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae_scaling_factor_image \u001b[38;5;241m*\u001b[39m latents\n\u001b[0;32m--> 350\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frames\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/utils/accelerate_utils.py:46\u001b[0m, in \u001b[0;36mapply_forward_hook.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hf_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_hook, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpre_forward(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:1279\u001b[0m, in \u001b[0;36mAutoencoderKLCogVideoX.decode\u001b[0;34m(self, z, return_dict)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(decoded_slices)\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1279\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (decoded,)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:1250\u001b[0m, in \u001b[0;36mAutoencoderKLCogVideoX._decode\u001b[0;34m(self, z, return_dict)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_quant_conv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1249\u001b[0m         z_intermediate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_quant_conv(z_intermediate)\n\u001b[0;32m-> 1250\u001b[0m     z_intermediate, conv_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_intermediate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m     dec\u001b[38;5;241m.\u001b[39mappend(z_intermediate)\n\u001b[1;32m   1253\u001b[0m dec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(dec, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:970\u001b[0m, in \u001b[0;36mCogVideoXDecoder3D.forward\u001b[0;34m(self, sample, temb, conv_cache)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, up_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_blocks):\n\u001b[1;32m    969\u001b[0m         conv_cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup_block_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 970\u001b[0m         hidden_states, new_conv_cache[conv_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[43mup_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_cache_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# 3. Post-process\u001b[39;00m\n\u001b[1;32m    975\u001b[0m hidden_states, new_conv_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm_out\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_out(\n\u001b[1;32m    976\u001b[0m     hidden_states, sample, conv_cache\u001b[38;5;241m=\u001b[39mconv_cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm_out\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    977\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:647\u001b[0m, in \u001b[0;36mCogVideoXUpBlock3D.forward\u001b[0;34m(self, hidden_states, temb, zq, conv_cache)\u001b[0m\n\u001b[1;32m    639\u001b[0m         hidden_states, new_conv_cache[conv_cache_key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    640\u001b[0m             create_custom_forward(resnet),\n\u001b[1;32m    641\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m             conv_cache\u001b[38;5;241m=\u001b[39mconv_cache\u001b[38;5;241m.\u001b[39mget(conv_cache_key),\n\u001b[1;32m    645\u001b[0m         )\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 647\u001b[0m         hidden_states, new_conv_cache[conv_cache_key] \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_cache_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:296\u001b[0m, in \u001b[0;36mCogVideoXResnetBlock3D.forward\u001b[0;34m(self, inputs, temb, zq, conv_cache)\u001b[0m\n\u001b[1;32m    293\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(hidden_states)\n\u001b[1;32m    295\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(hidden_states)\n\u001b[0;32m--> 296\u001b[0m hidden_states, new_conv_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m temb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemb_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlinearity(temb))[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/models/autoencoders/autoencoder_kl_cogvideox.py:134\u001b[0m, in \u001b[0;36mCogVideoXCausalConv3d.forward\u001b[0;34m(self, inputs, conv_cache)\u001b[0m\n\u001b[1;32m    131\u001b[0m conv_cache \u001b[38;5;241m=\u001b[39m inputs[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_kernel_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    133\u001b[0m padding_2d \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth_pad, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth_pad, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight_pad, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight_pad)\n\u001b[0;32m--> 134\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(inputs)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, conv_cache\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacty of 44.34 GiB of which 86.81 MiB is free. Process 660831 has 44.25 GiB memory in use. Of the allocated memory 43.35 GiB is allocated by PyTorch, and 587.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "out = pipe.decode_latents(video.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3abd5593-8ebf-4484-b70f-ac4505e33de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 16, 60, 90])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1f1cad-18dc-4832-b63f-c5af7259a788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 29 15:30:16 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A40                     On  |   00000000:57:00.0 Off |                    0 |\n",
      "|  0%   39C    P0             76W /  300W |   32855MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
